('out_directory: '
 './experiments/compound/MLP_2/1469983670_128/wandb/run-20240122_004058-01bw4t5e/files')
[0.02453401 0.03125942 0.0345386  0.03764214 0.04093086 0.04446986
 0.04818354 0.05225137 0.05619733 0.06024901 0.06437044 0.06905013
 0.0695655  0.07238108 0.07191995 0.06708655 0.04676306 0.06179548
 0.02241653 0.02439502]
/nethome/wmu30/anaconda3/envs/design-baseliness/lib/python3.7/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py:53: LightningDeprecationWarning: Setting `max_steps = None` is deprecated in v1.5 and will no longer be supported in v1.7. Use `max_steps = -1` instead.
  "Setting `max_steps = None` is deprecated in v1.5 and will no longer be supported in v1.7."
/nethome/wmu30/anaconda3/envs/design-baseliness/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:97: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=20)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.
  f"Setting `Trainer(progress_bar_refresh_rate={progress_bar_refresh_rate})` is deprecated in v1.5 and"
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
Sanity Checking DataLoader 0:   0%|                                                                                    | 0/2 [00:00<?, ?it/s]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [4]
  | Name    | Type                  | Params
--------------------------------------------------
0 | mlp     | MLP                   | 2.1 M
1 | inf_sde | VariancePreservingSDE | 1
--------------------------------------------------
2.1 M     Trainable params
1         Non-trainable params
2.1 M     Total params




Epoch 3:  76%|████████████████████████████         | 60/79 [00:01<00:00, 40.70it/s, loss=0.498, v_num=4t5e, train_loss=0.303, val_loss=0.549]




Epoch 7:  76%|████████████████████████████         | 60/79 [00:01<00:00, 47.60it/s, loss=0.492, v_num=4t5e, train_loss=0.315, val_loss=0.565]





Epoch 12:  76%|███████████████████████████▎        | 60/79 [00:01<00:00, 43.54it/s, loss=0.499, v_num=4t5e, train_loss=0.348, val_loss=0.525]




Epoch 16:  76%|███████████████████████████▎        | 60/79 [00:01<00:00, 39.19it/s, loss=0.463, v_num=4t5e, train_loss=0.321, val_loss=0.486]




Epoch 20:  76%|███████████████████████████▎        | 60/79 [00:01<00:00, 40.45it/s, loss=0.453, v_num=4t5e, train_loss=0.250, val_loss=0.531]



Epoch 23:  76%|████████████████████████████         | 60/79 [00:01<00:00, 38.05it/s, loss=0.45, v_num=4t5e, train_loss=0.295, val_loss=0.509]




Epoch 27:  76%|███████████████████████████▎        | 60/79 [00:01<00:00, 40.65it/s, loss=0.449, v_num=4t5e, train_loss=0.306, val_loss=0.484]



Epoch 30:  76%|███████████████████████████▎        | 60/79 [00:01<00:00, 40.36it/s, loss=0.427, v_num=4t5e, train_loss=0.394, val_loss=0.508]




Epoch 34:  76%|███████████████████████████▎        | 60/79 [00:01<00:00, 44.81it/s, loss=0.383, v_num=4t5e, train_loss=0.450, val_loss=0.533]


Epoch 37:  76%|███████████████████████████▎        | 60/79 [00:01<00:00, 41.13it/s, loss=0.399, v_num=4t5e, train_loss=0.407, val_loss=0.511]



Epoch 40:  76%|███████████████████████████▎        | 60/79 [00:01<00:00, 42.11it/s, loss=0.363, v_num=4t5e, train_loss=0.365, val_loss=0.564]



Epoch 43:  76%|███████████████████████████▎        | 60/79 [00:01<00:00, 40.16it/s, loss=0.368, v_num=4t5e, train_loss=0.259, val_loss=0.531]




Epoch 47:  76%|███████████████████████████▎        | 60/79 [00:01<00:00, 39.09it/s, loss=0.322, v_num=4t5e, train_loss=0.240, val_loss=0.534]



Epoch 50:  76%|███████████████████████████▎        | 60/79 [00:01<00:00, 39.86it/s, loss=0.361, v_num=4t5e, train_loss=0.309, val_loss=0.537]




Epoch 54:  76%|███████████████████████████▎        | 60/79 [00:01<00:00, 43.74it/s, loss=0.336, v_num=4t5e, train_loss=0.273, val_loss=0.564]



Epoch 57:  76%|███████████████████████████▎        | 60/79 [00:01<00:00, 38.88it/s, loss=0.332, v_num=4t5e, train_loss=0.247, val_loss=0.536]



Epoch 60:  76%|███████████████████████████▎        | 60/79 [00:01<00:00, 39.78it/s, loss=0.323, v_num=4t5e, train_loss=0.324, val_loss=0.526]



Epoch 63:  76%|███████████████████████████▎        | 60/79 [00:01<00:00, 39.75it/s, loss=0.317, v_num=4t5e, train_loss=0.347, val_loss=0.522]




Epoch 67:  76%|████████████████████████████         | 60/79 [00:01<00:00, 39.03it/s, loss=0.34, v_num=4t5e, train_loss=0.307, val_loss=0.515]



Epoch 70:  76%|███████████████████████████▎        | 60/79 [00:01<00:00, 37.82it/s, loss=0.307, v_num=4t5e, train_loss=0.221, val_loss=0.555]


Epoch 72:  76%|███████████████████████████▎        | 60/79 [00:01<00:00, 39.67it/s, loss=0.331, v_num=4t5e, train_loss=0.230, val_loss=0.491]


Epoch 75:  76%|████████████████████████████         | 60/79 [00:01<00:00, 40.80it/s, loss=0.31, v_num=4t5e, train_loss=0.173, val_loss=0.466]




Epoch 79:  76%|███████████████████████████▎        | 60/79 [00:01<00:00, 43.10it/s, loss=0.299, v_num=4t5e, train_loss=0.257, val_loss=0.493]




Epoch 83:  76%|███████████████████████████▎        | 60/79 [00:01<00:00, 40.49it/s, loss=0.303, v_num=4t5e, train_loss=0.321, val_loss=0.519]



Epoch 86:  76%|███████████████████████████▎        | 60/79 [00:01<00:00, 36.94it/s, loss=0.304, v_num=4t5e, train_loss=0.243, val_loss=0.515]



Epoch 89:  76%|███████████████████████████▎        | 60/79 [00:01<00:00, 39.87it/s, loss=0.301, v_num=4t5e, train_loss=0.202, val_loss=0.534]



Epoch 92:  76%|███████████████████████████▎        | 60/79 [00:01<00:00, 39.90it/s, loss=0.288, v_num=4t5e, train_loss=0.215, val_loss=0.520]



Epoch 95:  76%|████████████████████████████         | 60/79 [00:01<00:00, 37.26it/s, loss=0.31, v_num=4t5e, train_loss=0.221, val_loss=0.478]



Epoch 98:  76%|███████████████████████████▎        | 60/79 [00:01<00:00, 38.74it/s, loss=0.289, v_num=4t5e, train_loss=0.218, val_loss=0.507]



Epoch 101:  76%|██████████████████████████▌        | 60/79 [00:01<00:00, 36.43it/s, loss=0.286, v_num=4t5e, train_loss=0.203, val_loss=0.537]







Epoch 107:  76%|██████████████████████████▌        | 60/79 [00:01<00:00, 39.78it/s, loss=0.305, v_num=4t5e, train_loss=0.227, val_loss=0.536]



Epoch 110:  76%|██████████████████████████▌        | 60/79 [00:01<00:00, 38.81it/s, loss=0.271, v_num=4t5e, train_loss=0.223, val_loss=0.514]




Epoch 114:  76%|██████████████████████████▌        | 60/79 [00:01<00:00, 41.46it/s, loss=0.282, v_num=4t5e, train_loss=0.231, val_loss=0.491]



Epoch 117:  76%|██████████████████████████▌        | 60/79 [00:01<00:00, 37.63it/s, loss=0.307, v_num=4t5e, train_loss=0.279, val_loss=0.529]



Epoch 120:  76%|██████████████████████████▌        | 60/79 [00:01<00:00, 40.15it/s, loss=0.292, v_num=4t5e, train_loss=0.212, val_loss=0.525]



Epoch 123:  76%|██████████████████████████▌        | 60/79 [00:01<00:00, 42.44it/s, loss=0.292, v_num=4t5e, train_loss=0.187, val_loss=0.530]



Epoch 126:  76%|██████████████████████████▌        | 60/79 [00:01<00:00, 40.34it/s, loss=0.281, v_num=4t5e, train_loss=0.202, val_loss=0.478]



Epoch 129:  76%|██████████████████████████▌        | 60/79 [00:01<00:00, 41.50it/s, loss=0.268, v_num=4t5e, train_loss=0.210, val_loss=0.548]



Epoch 132:  76%|███████████████████████████▎        | 60/79 [00:01<00:00, 37.38it/s, loss=0.27, v_num=4t5e, train_loss=0.237, val_loss=0.524]




Epoch 136:  76%|██████████████████████████▌        | 60/79 [00:01<00:00, 41.23it/s, loss=0.247, v_num=4t5e, train_loss=0.176, val_loss=0.528]


Epoch 138:  76%|██████████████████████████▌        | 60/79 [00:01<00:00, 39.81it/s, loss=0.301, v_num=4t5e, train_loss=0.186, val_loss=0.570]



Epoch 141: 100%|███████████████████████████████████| 79/79 [00:02<00:00, 34.15it/s, loss=0.265, v_num=4t5e, train_loss=0.173, val_loss=0.549]




Epoch 145:  76%|██████████████████████████▌        | 60/79 [00:01<00:00, 41.38it/s, loss=0.278, v_num=4t5e, train_loss=0.282, val_loss=0.527]


Epoch 147:  76%|██████████████████████████▌        | 60/79 [00:01<00:00, 39.89it/s, loss=0.304, v_num=4t5e, train_loss=0.198, val_loss=0.520]



Epoch 150:  76%|██████████████████████████▌        | 60/79 [00:01<00:00, 41.28it/s, loss=0.265, v_num=4t5e, train_loss=0.216, val_loss=0.507]




Epoch 154:  76%|██████████████████████████▌        | 60/79 [00:01<00:00, 40.94it/s, loss=0.264, v_num=4t5e, train_loss=0.159, val_loss=0.506]



Epoch 157:  76%|██████████████████████████▌        | 60/79 [00:01<00:00, 40.84it/s, loss=0.288, v_num=4t5e, train_loss=0.195, val_loss=0.542]



Epoch 160:  76%|██████████████████████████▌        | 60/79 [00:01<00:00, 40.87it/s, loss=0.258, v_num=4t5e, train_loss=0.187, val_loss=0.527]




Epoch 164:  76%|██████████████████████████▌        | 60/79 [00:01<00:00, 41.03it/s, loss=0.293, v_num=4t5e, train_loss=0.206, val_loss=0.508]



Epoch 167:  76%|██████████████████████████▌        | 60/79 [00:01<00:00, 34.59it/s, loss=0.307, v_num=4t5e, train_loss=0.253, val_loss=0.527]



Epoch 170:  76%|██████████████████████████▌        | 60/79 [00:01<00:00, 39.05it/s, loss=0.261, v_num=4t5e, train_loss=0.217, val_loss=0.501]



Epoch 173:  76%|██████████████████████████▌        | 60/79 [00:01<00:00, 42.96it/s, loss=0.264, v_num=4t5e, train_loss=0.186, val_loss=0.525]



Epoch 176:  76%|██████████████████████████▌        | 60/79 [00:01<00:00, 37.02it/s, loss=0.277, v_num=4t5e, train_loss=0.261, val_loss=0.511]


Epoch 178:  76%|██████████████████████████▌        | 60/79 [00:01<00:00, 38.85it/s, loss=0.259, v_num=4t5e, train_loss=0.176, val_loss=0.481]




Epoch 182:  76%|██████████████████████████▌        | 60/79 [00:01<00:00, 44.16it/s, loss=0.261, v_num=4t5e, train_loss=0.146, val_loss=0.531]



Epoch 185:  76%|██████████████████████████▌        | 60/79 [00:01<00:00, 37.94it/s, loss=0.264, v_num=4t5e, train_loss=0.187, val_loss=0.492]




Epoch 189:  76%|██████████████████████████▌        | 60/79 [00:01<00:00, 41.92it/s, loss=0.254, v_num=4t5e, train_loss=0.209, val_loss=0.570]



Epoch 192:  76%|██████████████████████████▌        | 60/79 [00:01<00:00, 39.87it/s, loss=0.252, v_num=4t5e, train_loss=0.167, val_loss=0.540]




Epoch 196:  76%|██████████████████████████▌        | 60/79 [00:01<00:00, 42.21it/s, loss=0.259, v_num=4t5e, train_loss=0.194, val_loss=0.525]



Epoch 199:  76%|██████████████████████████▌        | 60/79 [00:01<00:00, 39.95it/s, loss=0.274, v_num=4t5e, train_loss=0.214, val_loss=0.518]

Validation: 0it [00:00, ?it/s]