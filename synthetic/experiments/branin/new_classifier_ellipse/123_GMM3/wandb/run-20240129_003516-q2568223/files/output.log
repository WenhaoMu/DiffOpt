('out_directory: '
 './experiments/branin/new_classifier_ellipse/123_GMM3/wandb/run-20240129_003516-q2568223/files')
shapesss (6040, 2) (1, 6040, 1)
shapesss (6040, 2) (6040, 1)
[8.40824839e-21 9.66923258e-20 1.11254525e-18 1.28087196e-17
 1.47931871e-16 1.70184561e-15 1.95155433e-14 2.24314893e-13
 2.57221530e-12 2.95893976e-11 3.40580609e-10 3.86106714e-09
 4.40428979e-08 4.98776984e-07 5.61496433e-06 6.32810815e-05
 7.38673042e-04 8.06684931e-03 9.10087297e-02 9.00116169e-01]
/nethome/wmu30/anaconda3/envs/design-baseliness/lib/python3.7/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py:53: LightningDeprecationWarning: Setting `max_steps = None` is deprecated in v1.5 and will no longer be supported in v1.7. Use `max_steps = -1` instead.
  "Setting `max_steps = None` is deprecated in v1.5 and will no longer be supported in v1.7."
/nethome/wmu30/anaconda3/envs/design-baseliness/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:97: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=20)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.
  f"Setting `Trainer(progress_bar_refresh_rate={progress_bar_refresh_rate})` is deprecated in v1.5 and"
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
Sanity Checking DataLoader 0:   0%|                                                                           | 0/2 [00:00<?, ?it/s]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]
  | Name    | Type                  | Params
--------------------------------------------------
0 | mlp     | MLP                   | 2.1 M
1 | inf_sde | VariancePreservingSDE | 1
--------------------------------------------------
2.1 M     Trainable params
1         Non-trainable params
2.1 M     Total params

Epoch 0: 100%|████████████████████████████| 25/25 [00:01<00:00, 17.78it/s, loss=0.797, v_num=8223, train_loss=0.923, val_loss=0.693]
/nethome/wmu30/anaconda3/envs/design-baseliness/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py:1937: PossibleUserWarning: The number of training batches (22) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.






Epoch 8:  80%|██████████████████████▍     | 20/25 [00:00<00:00, 21.48it/s, loss=0.588, v_num=8223, train_loss=0.722, val_loss=0.605]





Epoch 16:  80%|█████████████████████▌     | 20/25 [00:01<00:00, 19.27it/s, loss=0.573, v_num=8223, train_loss=0.692, val_loss=0.534]





Epoch 24:  80%|█████████████████████▌     | 20/25 [00:00<00:00, 21.44it/s, loss=0.574, v_num=8223, train_loss=0.582, val_loss=0.555]





Epoch 32:  80%|█████████████████████▌     | 20/25 [00:00<00:00, 21.87it/s, loss=0.571, v_num=8223, train_loss=0.522, val_loss=0.560]




Epoch 39:  80%|█████████████████████▌     | 20/25 [00:00<00:00, 21.58it/s, loss=0.557, v_num=8223, train_loss=0.584, val_loss=0.540]





Epoch 47:  80%|█████████████████████▌     | 20/25 [00:01<00:00, 19.72it/s, loss=0.562, v_num=8223, train_loss=0.585, val_loss=0.571]





Epoch 56:  80%|█████████████████████▌     | 20/25 [00:00<00:00, 20.46it/s, loss=0.578, v_num=8223, train_loss=0.559, val_loss=0.512]

Epoch 60:  80%|█████████████████████▌     | 20/25 [00:00<00:00, 20.59it/s, loss=0.562, v_num=8223, train_loss=0.549, val_loss=0.550]





Epoch 67:  80%|█████████████████████▌     | 20/25 [00:00<00:00, 21.91it/s, loss=0.554, v_num=8223, train_loss=0.624, val_loss=0.584]






Epoch 76:  80%|█████████████████████▌     | 20/25 [00:00<00:00, 21.15it/s, loss=0.572, v_num=8223, train_loss=0.513, val_loss=0.536]




Epoch 84:  80%|█████████████████████▌     | 20/25 [00:00<00:00, 20.95it/s, loss=0.551, v_num=8223, train_loss=0.674, val_loss=0.567]





Epoch 91:  80%|█████████████████████▌     | 20/25 [00:00<00:00, 23.06it/s, loss=0.553, v_num=8223, train_loss=0.543, val_loss=0.535]





Epoch 99:  80%|█████████████████████▌     | 20/25 [00:00<00:00, 21.40it/s, loss=0.563, v_num=8223, train_loss=0.560, val_loss=0.592]






Epoch 109:  80%|████████████████████▊     | 20/25 [00:00<00:00, 22.15it/s, loss=0.559, v_num=8223, train_loss=0.492, val_loss=0.597]




Epoch 116:  80%|█████████████████████▌     | 20/25 [00:00<00:00, 21.22it/s, loss=0.56, v_num=8223, train_loss=0.651, val_loss=0.526]






Epoch 124:  80%|████████████████████▊     | 20/25 [00:00<00:00, 22.55it/s, loss=0.561, v_num=8223, train_loss=0.566, val_loss=0.563]


Epoch 127:  80%|████████████████████▊     | 20/25 [00:00<00:00, 21.09it/s, loss=0.576, v_num=8223, train_loss=0.533, val_loss=0.514]







Epoch 137:  80%|█████████████████████▌     | 20/25 [00:00<00:00, 21.44it/s, loss=0.56, v_num=8223, train_loss=0.560, val_loss=0.573]







Epoch 148:  80%|████████████████████▊     | 20/25 [00:00<00:00, 20.21it/s, loss=0.546, v_num=8223, train_loss=0.567, val_loss=0.589]






Epoch 158:  80%|████████████████████▊     | 20/25 [00:01<00:00, 19.26it/s, loss=0.551, v_num=8223, train_loss=0.522, val_loss=0.562]







Epoch 168:  80%|████████████████████▊     | 20/25 [00:00<00:00, 20.18it/s, loss=0.572, v_num=8223, train_loss=0.537, val_loss=0.585]






Epoch 178:  80%|████████████████████▊     | 20/25 [00:00<00:00, 21.55it/s, loss=0.543, v_num=8223, train_loss=0.503, val_loss=0.549]







Epoch 189:  80%|████████████████████▊     | 20/25 [00:00<00:00, 21.49it/s, loss=0.561, v_num=8223, train_loss=0.545, val_loss=0.531]

Epoch 191:  80%|████████████████████▊     | 20/25 [00:00<00:00, 21.26it/s, loss=0.557, v_num=8223, train_loss=0.530, val_loss=0.559]





Epoch 199:  80%|████████████████████▊     | 20/25 [00:00<00:00, 20.80it/s, loss=0.564, v_num=8223, train_loss=0.579, val_loss=0.541]




Epoch 207:  80%|████████████████████▊     | 20/25 [00:01<00:00, 18.34it/s, loss=0.563, v_num=8223, train_loss=0.589, val_loss=0.552]






Epoch 217:  80%|████████████████████▊     | 20/25 [00:00<00:00, 20.99it/s, loss=0.546, v_num=8223, train_loss=0.573, val_loss=0.566]






Epoch 226:  80%|████████████████████▊     | 20/25 [00:00<00:00, 20.94it/s, loss=0.572, v_num=8223, train_loss=0.489, val_loss=0.560]







Epoch 237:  80%|█████████████████████▌     | 20/25 [00:01<00:00, 19.61it/s, loss=0.55, v_num=8223, train_loss=0.526, val_loss=0.521]





Epoch 246:  80%|████████████████████▊     | 20/25 [00:01<00:00, 19.89it/s, loss=0.564, v_num=8223, train_loss=0.536, val_loss=0.555]




Epoch 253:  80%|████████████████████▊     | 20/25 [00:00<00:00, 22.44it/s, loss=0.546, v_num=8223, train_loss=0.498, val_loss=0.500]

Epoch 256:  80%|█████████████████████▌     | 20/25 [00:00<00:00, 22.47it/s, loss=0.56, v_num=8223, train_loss=0.532, val_loss=0.520]





Epoch 264:  80%|████████████████████▊     | 20/25 [00:00<00:00, 21.20it/s, loss=0.534, v_num=8223, train_loss=0.494, val_loss=0.495]





Epoch 274:  80%|████████████████████▊     | 20/25 [00:00<00:00, 20.28it/s, loss=0.555, v_num=8223, train_loss=0.530, val_loss=0.544]






Epoch 283:  80%|████████████████████▊     | 20/25 [00:00<00:00, 21.93it/s, loss=0.581, v_num=8223, train_loss=0.510, val_loss=0.621]





Epoch 290:  80%|█████████████████████▌     | 20/25 [00:00<00:00, 20.80it/s, loss=0.56, v_num=8223, train_loss=0.634, val_loss=0.473]





Epoch 298:  80%|████████████████████▊     | 20/25 [00:00<00:00, 21.06it/s, loss=0.562, v_num=8223, train_loss=0.615, val_loss=0.499]




Epoch 306:  80%|████████████████████▊     | 20/25 [00:00<00:00, 23.28it/s, loss=0.566, v_num=8223, train_loss=0.583, val_loss=0.540]






Epoch 315:  80%|████████████████████▊     | 20/25 [00:00<00:00, 20.38it/s, loss=0.548, v_num=8223, train_loss=0.473, val_loss=0.543]

Epoch 317:  80%|████████████████████▊     | 20/25 [00:00<00:00, 20.96it/s, loss=0.565, v_num=8223, train_loss=0.517, val_loss=0.560]




Epoch 324:  80%|█████████████████████▌     | 20/25 [00:00<00:00, 21.86it/s, loss=0.54, v_num=8223, train_loss=0.473, val_loss=0.508]



Epoch 330:  80%|████████████████████▊     | 20/25 [00:00<00:00, 21.70it/s, loss=0.564, v_num=8223, train_loss=0.583, val_loss=0.539]





Epoch 339:  80%|████████████████████▊     | 20/25 [00:00<00:00, 23.34it/s, loss=0.546, v_num=8223, train_loss=0.534, val_loss=0.552]





Epoch 346:  80%|████████████████████▊     | 20/25 [00:00<00:00, 20.88it/s, loss=0.567, v_num=8223, train_loss=0.528, val_loss=0.568]






Epoch 355:  80%|█████████████████████▌     | 20/25 [00:00<00:00, 20.32it/s, loss=0.56, v_num=8223, train_loss=0.494, val_loss=0.559]




Epoch 363:  80%|████████████████████▊     | 20/25 [00:00<00:00, 22.12it/s, loss=0.554, v_num=8223, train_loss=0.463, val_loss=0.581]




Epoch 371:  80%|████████████████████▊     | 20/25 [00:00<00:00, 21.18it/s, loss=0.566, v_num=8223, train_loss=0.638, val_loss=0.528]








Epoch 383:  80%|████████████████████▊     | 20/25 [00:00<00:00, 21.83it/s, loss=0.566, v_num=8223, train_loss=0.453, val_loss=0.528]






Epoch 393:  80%|████████████████████▊     | 20/25 [00:00<00:00, 22.00it/s, loss=0.561, v_num=8223, train_loss=0.543, val_loss=0.552]






Epoch 402:  80%|████████████████████▊     | 20/25 [00:00<00:00, 20.71it/s, loss=0.576, v_num=8223, train_loss=0.544, val_loss=0.563]






Epoch 411:  80%|████████████████████▊     | 20/25 [00:00<00:00, 22.87it/s, loss=0.538, v_num=8223, train_loss=0.564, val_loss=0.580]





Epoch 419:  80%|████████████████████▊     | 20/25 [00:00<00:00, 22.18it/s, loss=0.574, v_num=8223, train_loss=0.500, val_loss=0.540]






Epoch 427:  80%|█████████████████████▌     | 20/25 [00:00<00:00, 21.75it/s, loss=0.53, v_num=8223, train_loss=0.509, val_loss=0.559]





Epoch 435:  80%|████████████████████▊     | 20/25 [00:00<00:00, 22.93it/s, loss=0.532, v_num=8223, train_loss=0.543, val_loss=0.591]








Epoch 445:  80%|████████████████████▊     | 20/25 [00:00<00:00, 21.53it/s, loss=0.568, v_num=8223, train_loss=0.584, val_loss=0.473]





Epoch 453:  80%|████████████████████▊     | 20/25 [00:00<00:00, 20.60it/s, loss=0.576, v_num=8223, train_loss=0.559, val_loss=0.529]





Epoch 460:  80%|████████████████████▊     | 20/25 [00:00<00:00, 21.27it/s, loss=0.555, v_num=8223, train_loss=0.507, val_loss=0.506]




Epoch 467:  80%|████████████████████▊     | 20/25 [00:00<00:00, 22.52it/s, loss=0.573, v_num=8223, train_loss=0.631, val_loss=0.550]





Epoch 475:  80%|█████████████████████▌     | 20/25 [00:00<00:00, 23.27it/s, loss=0.55, v_num=8223, train_loss=0.529, val_loss=0.584]




Epoch 482:  80%|████████████████████▊     | 20/25 [00:01<00:00, 18.63it/s, loss=0.549, v_num=8223, train_loss=0.593, val_loss=0.531]






Epoch 492:  80%|████████████████████▊     | 20/25 [00:00<00:00, 23.03it/s, loss=0.571, v_num=8223, train_loss=0.595, val_loss=0.537]






Epoch 501:  80%|████████████████████▊     | 20/25 [00:00<00:00, 20.87it/s, loss=0.561, v_num=8223, train_loss=0.467, val_loss=0.526]




Epoch 513:  80%|████████████████████▊     | 20/25 [00:00<00:00, 21.50it/s, loss=0.574, v_num=8223, train_loss=0.491, val_loss=0.550]






Epoch 522:  80%|████████████████████▊     | 20/25 [00:00<00:00, 21.20it/s, loss=0.577, v_num=8223, train_loss=0.526, val_loss=0.538]




Epoch 529:  80%|████████████████████▊     | 20/25 [00:00<00:00, 20.34it/s, loss=0.552, v_num=8223, train_loss=0.601, val_loss=0.512]




Epoch 538:  80%|████████████████████▊     | 20/25 [00:00<00:00, 21.33it/s, loss=0.572, v_num=8223, train_loss=0.507, val_loss=0.546]






Epoch 548:  80%|████████████████████▊     | 20/25 [00:00<00:00, 21.87it/s, loss=0.552, v_num=8223, train_loss=0.536, val_loss=0.554]






Epoch 557:  80%|████████████████████▊     | 20/25 [00:01<00:00, 19.79it/s, loss=0.553, v_num=8223, train_loss=0.453, val_loss=0.545]










Epoch 571:  80%|████████████████████▊     | 20/25 [00:00<00:00, 20.87it/s, loss=0.557, v_num=8223, train_loss=0.561, val_loss=0.584]






Epoch 580:  80%|████████████████████▊     | 20/25 [00:00<00:00, 21.38it/s, loss=0.565, v_num=8223, train_loss=0.591, val_loss=0.511]






Epoch 589:  80%|████████████████████▊     | 20/25 [00:00<00:00, 20.90it/s, loss=0.549, v_num=8223, train_loss=0.581, val_loss=0.553]







Epoch 600:  80%|████████████████████▊     | 20/25 [00:00<00:00, 20.58it/s, loss=0.554, v_num=8223, train_loss=0.616, val_loss=0.556]







Epoch 611:  80%|████████████████████▊     | 20/25 [00:00<00:00, 21.56it/s, loss=0.564, v_num=8223, train_loss=0.484, val_loss=0.521]













Epoch 627:  80%|████████████████████▊     | 20/25 [00:00<00:00, 21.44it/s, loss=0.561, v_num=8223, train_loss=0.606, val_loss=0.485]







Epoch 637:  80%|████████████████████▊     | 20/25 [00:00<00:00, 21.00it/s, loss=0.549, v_num=8223, train_loss=0.611, val_loss=0.536]






Epoch 645:  80%|████████████████████▊     | 20/25 [00:01<00:00, 19.62it/s, loss=0.554, v_num=8223, train_loss=0.563, val_loss=0.539]





Epoch 654:  80%|████████████████████▊     | 20/25 [00:00<00:00, 20.30it/s, loss=0.568, v_num=8223, train_loss=0.648, val_loss=0.492]





Epoch 662:  80%|████████████████████▊     | 20/25 [00:00<00:00, 22.18it/s, loss=0.565, v_num=8223, train_loss=0.565, val_loss=0.534]






Epoch 670:  80%|████████████████████▊     | 20/25 [00:00<00:00, 22.66it/s, loss=0.561, v_num=8223, train_loss=0.609, val_loss=0.571]






Epoch 680:  80%|████████████████████▊     | 20/25 [00:00<00:00, 21.79it/s, loss=0.578, v_num=8223, train_loss=0.571, val_loss=0.498]






Epoch 689:  80%|████████████████████▊     | 20/25 [00:00<00:00, 21.02it/s, loss=0.532, v_num=8223, train_loss=0.532, val_loss=0.512]





Epoch 695:  80%|████████████████████▊     | 20/25 [00:01<00:00, 14.74it/s, loss=0.566, v_num=8223, train_loss=0.575, val_loss=0.538]


Epoch 698:  80%|████████████████████▊     | 20/25 [00:00<00:00, 22.61it/s, loss=0.557, v_num=8223, train_loss=0.484, val_loss=0.562]








Epoch 709:  80%|█████████████████████▌     | 20/25 [00:00<00:00, 21.01it/s, loss=0.56, v_num=8223, train_loss=0.534, val_loss=0.567]







Epoch 722:  80%|████████████████████▊     | 20/25 [00:00<00:00, 20.19it/s, loss=0.572, v_num=8223, train_loss=0.535, val_loss=0.521]









Epoch 734:  80%|████████████████████▊     | 20/25 [00:00<00:00, 22.05it/s, loss=0.564, v_num=8223, train_loss=0.534, val_loss=0.544]







Epoch 744:  80%|████████████████████▊     | 20/25 [00:00<00:00, 20.91it/s, loss=0.531, v_num=8223, train_loss=0.551, val_loss=0.515]

Epoch 746:  80%|████████████████████▊     | 20/25 [00:00<00:00, 20.42it/s, loss=0.536, v_num=8223, train_loss=0.596, val_loss=0.513]







Epoch 758:  80%|████████████████████▊     | 20/25 [00:00<00:00, 20.75it/s, loss=0.538, v_num=8223, train_loss=0.542, val_loss=0.531]







Epoch 768:  80%|████████████████████▊     | 20/25 [00:01<00:00, 19.81it/s, loss=0.544, v_num=8223, train_loss=0.584, val_loss=0.496]






Epoch 778:  80%|████████████████████▊     | 20/25 [00:01<00:00, 19.57it/s, loss=0.573, v_num=8223, train_loss=0.564, val_loss=0.566]








Epoch 791:  80%|████████████████████▊     | 20/25 [00:00<00:00, 21.38it/s, loss=0.559, v_num=8223, train_loss=0.508, val_loss=0.551]





Epoch 799:  80%|████████████████████▊     | 20/25 [00:00<00:00, 20.17it/s, loss=0.564, v_num=8223, train_loss=0.632, val_loss=0.527]











Epoch 813:  80%|████████████████████▊     | 20/25 [00:00<00:00, 20.06it/s, loss=0.557, v_num=8223, train_loss=0.584, val_loss=0.497]







Epoch 824:  80%|████████████████████▊     | 20/25 [00:01<00:00, 18.89it/s, loss=0.563, v_num=8223, train_loss=0.556, val_loss=0.538]







Epoch 835:  80%|█████████████████████▌     | 20/25 [00:01<00:00, 19.58it/s, loss=0.55, v_num=8223, train_loss=0.520, val_loss=0.552]








Epoch 847:  80%|████████████████████▊     | 20/25 [00:00<00:00, 20.04it/s, loss=0.562, v_num=8223, train_loss=0.546, val_loss=0.553]






Epoch 857:  80%|████████████████████▊     | 20/25 [00:00<00:00, 20.37it/s, loss=0.574, v_num=8223, train_loss=0.705, val_loss=0.525]






Epoch 868:  80%|████████████████████▊     | 20/25 [00:00<00:00, 20.09it/s, loss=0.564, v_num=8223, train_loss=0.527, val_loss=0.572]









Epoch 885:  80%|████████████████████▊     | 20/25 [00:01<00:00, 19.59it/s, loss=0.537, v_num=8223, train_loss=0.454, val_loss=0.541]






Epoch 895:  80%|████████████████████▊     | 20/25 [00:00<00:00, 22.48it/s, loss=0.555, v_num=8223, train_loss=0.527, val_loss=0.544]





Epoch 903:  80%|████████████████████▊     | 20/25 [00:00<00:00, 21.31it/s, loss=0.546, v_num=8223, train_loss=0.598, val_loss=0.578]






Epoch 913:  80%|████████████████████▊     | 20/25 [00:00<00:00, 21.51it/s, loss=0.555, v_num=8223, train_loss=0.551, val_loss=0.500]






Epoch 923:  80%|████████████████████▊     | 20/25 [00:00<00:00, 22.17it/s, loss=0.587, v_num=8223, train_loss=0.573, val_loss=0.503]











Epoch 938:  80%|████████████████████▊     | 20/25 [00:01<00:00, 19.77it/s, loss=0.562, v_num=8223, train_loss=0.579, val_loss=0.565]











Epoch 956:  80%|████████████████████▊     | 20/25 [00:00<00:00, 20.43it/s, loss=0.545, v_num=8223, train_loss=0.573, val_loss=0.515]











Epoch 973:  80%|████████████████████▊     | 20/25 [00:00<00:00, 21.48it/s, loss=0.561, v_num=8223, train_loss=0.512, val_loss=0.578]
























Epoch 999: 100%|██████████████████████████| 25/25 [00:01<00:00, 13.82it/s, loss=0.569, v_num=8223, train_loss=0.453, val_loss=0.630]