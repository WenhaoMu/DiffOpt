('out_directory: '
 './experiments/compound/multi/1469983670_noreweight/wandb/run-20230911_161651-0phgmte5/files')
Score matching loss
[0.00316918 0.0072529  0.01241131 0.01619215 0.01927074 0.02262353
 0.02631122 0.03051457 0.03533518 0.04085936 0.04722409 0.05451293
 0.06284052 0.07218581 0.08231845 0.09331833 0.10262941 0.10205275
 0.09619775 0.07277971]
[8.04357011e-05 1.55209298e-04 2.54620596e-04 4.14302588e-04
 6.38217224e-04 9.84181489e-04 1.50528217e-03 2.31866121e-03
 3.53105144e-03 5.40530577e-03 8.22762856e-03 1.25651040e-02
 1.91752106e-02 2.92109897e-02 4.44344599e-02 6.75275126e-02
 1.02493418e-01 1.55253617e-01 2.32940838e-01 3.12883848e-01]
[0.00728425 0.01237513 0.01647989 0.01936922 0.02239991 0.02568588
 0.02940139 0.03360057 0.03837965 0.04378923 0.04995495 0.05677969
 0.06451715 0.07293327 0.08162211 0.09029759 0.09688753 0.10286416
 0.08768646 0.04769183]
[[0.17098957]
 [0.21419156]
 [0.96522355]
 ...
 [0.7370875 ]
 [1.0167418 ]
 [0.3072307 ]]
(10000, 1)
/nethome/wmu30/anaconda3/envs/design-baseliness/lib/python3.7/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py:53: LightningDeprecationWarning: Setting `max_steps = None` is deprecated in v1.5 and will no longer be supported in v1.7. Use `max_steps = -1` instead.
  "Setting `max_steps = None` is deprecated in v1.5 and will no longer be supported in v1.7."
/nethome/wmu30/anaconda3/envs/design-baseliness/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:97: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=20)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.
  f"Setting `Trainer(progress_bar_refresh_rate={progress_bar_refresh_rate})` is deprecated in v1.5 and"
--- Logging error ---
Traceback (most recent call last):
  File "/nethome/wmu30/anaconda3/envs/design-baseliness/lib/python3.7/logging/__init__.py", line 1028, in emit
    stream.write(msg + self.terminator)
ValueError: I/O operation on closed file.
Call stack:
  File "design_baselines/diff_multi/trainer_amend_multi.py", line 1099, in <module>
    device=device,
  File "design_baselines/diff_multi/trainer_amend_multi.py", line 489, in run_training
    limit_test_batches=0,
  File "/nethome/wmu30/anaconda3/envs/design-baseliness/lib/python3.7/site-packages/pytorch_lightning/utilities/argparse.py", line 339, in insert_env_defaults
    return fn(self, **kwargs)
  File "/nethome/wmu30/anaconda3/envs/design-baseliness/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 606, in __init__
    self._setup_on_init(num_sanity_val_steps)
  File "/nethome/wmu30/anaconda3/envs/design-baseliness/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 687, in _setup_on_init
    self._log_device_info()
  File "/nethome/wmu30/anaconda3/envs/design-baseliness/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 1801, in _log_device_info
    f"GPU available: {torch.cuda.is_available()}, used: {isinstance(self.accelerator, GPUAccelerator)}"
  File "/nethome/wmu30/anaconda3/envs/design-baseliness/lib/python3.7/site-packages/pytorch_lightning/utilities/rank_zero.py", line 32, in wrapped_fn
    return fn(*args, **kwargs)
  File "/nethome/wmu30/anaconda3/envs/design-baseliness/lib/python3.7/site-packages/pytorch_lightning/utilities/rank_zero.py", line 75, in rank_zero_info
    _info(*args, stacklevel=stacklevel, **kwargs)
  File "/nethome/wmu30/anaconda3/envs/design-baseliness/lib/python3.7/site-packages/pytorch_lightning/utilities/rank_zero.py", line 57, in _info
    log.info(*args, **kwargs)
Message: 'GPU available: True, used: True'
Arguments: ()
--- Logging error ---
Traceback (most recent call last):
  File "/nethome/wmu30/anaconda3/envs/design-baseliness/lib/python3.7/logging/__init__.py", line 1028, in emit
    stream.write(msg + self.terminator)
ValueError: I/O operation on closed file.
Call stack:
  File "design_baselines/diff_multi/trainer_amend_multi.py", line 1099, in <module>
    device=device,
  File "design_baselines/diff_multi/trainer_amend_multi.py", line 489, in run_training
    limit_test_batches=0,
  File "/nethome/wmu30/anaconda3/envs/design-baseliness/lib/python3.7/site-packages/pytorch_lightning/utilities/argparse.py", line 339, in insert_env_defaults
    return fn(self, **kwargs)
  File "/nethome/wmu30/anaconda3/envs/design-baseliness/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 606, in __init__
    self._setup_on_init(num_sanity_val_steps)
  File "/nethome/wmu30/anaconda3/envs/design-baseliness/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 687, in _setup_on_init
    self._log_device_info()
  File "/nethome/wmu30/anaconda3/envs/design-baseliness/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 1805, in _log_device_info
    rank_zero_info(f"TPU available: {_TPU_AVAILABLE}, using: {num_tpu_cores} TPU cores")
  File "/nethome/wmu30/anaconda3/envs/design-baseliness/lib/python3.7/site-packages/pytorch_lightning/utilities/rank_zero.py", line 32, in wrapped_fn
    return fn(*args, **kwargs)
  File "/nethome/wmu30/anaconda3/envs/design-baseliness/lib/python3.7/site-packages/pytorch_lightning/utilities/rank_zero.py", line 75, in rank_zero_info
    _info(*args, stacklevel=stacklevel, **kwargs)
  File "/nethome/wmu30/anaconda3/envs/design-baseliness/lib/python3.7/site-packages/pytorch_lightning/utilities/rank_zero.py", line 57, in _info
    log.info(*args, **kwargs)
Message: 'TPU available: False, using: 0 TPU cores'
Arguments: ()
--- Logging error ---
Traceback (most recent call last):
  File "/nethome/wmu30/anaconda3/envs/design-baseliness/lib/python3.7/logging/__init__.py", line 1028, in emit
    stream.write(msg + self.terminator)
ValueError: I/O operation on closed file.
Call stack:
  File "design_baselines/diff_multi/trainer_amend_multi.py", line 1099, in <module>
    device=device,
  File "design_baselines/diff_multi/trainer_amend_multi.py", line 489, in run_training
    limit_test_batches=0,
  File "/nethome/wmu30/anaconda3/envs/design-baseliness/lib/python3.7/site-packages/pytorch_lightning/utilities/argparse.py", line 339, in insert_env_defaults
    return fn(self, **kwargs)
  File "/nethome/wmu30/anaconda3/envs/design-baseliness/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 606, in __init__
    self._setup_on_init(num_sanity_val_steps)
  File "/nethome/wmu30/anaconda3/envs/design-baseliness/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 687, in _setup_on_init
    self._log_device_info()
  File "/nethome/wmu30/anaconda3/envs/design-baseliness/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 1808, in _log_device_info
    rank_zero_info(f"IPU available: {_IPU_AVAILABLE}, using: {num_ipus} IPUs")
  File "/nethome/wmu30/anaconda3/envs/design-baseliness/lib/python3.7/site-packages/pytorch_lightning/utilities/rank_zero.py", line 32, in wrapped_fn
    return fn(*args, **kwargs)
  File "/nethome/wmu30/anaconda3/envs/design-baseliness/lib/python3.7/site-packages/pytorch_lightning/utilities/rank_zero.py", line 75, in rank_zero_info
    _info(*args, stacklevel=stacklevel, **kwargs)
  File "/nethome/wmu30/anaconda3/envs/design-baseliness/lib/python3.7/site-packages/pytorch_lightning/utilities/rank_zero.py", line 57, in _info
    log.info(*args, **kwargs)
Message: 'IPU available: False, using: 0 IPUs'
Arguments: ()
--- Logging error ---
Traceback (most recent call last):
  File "/nethome/wmu30/anaconda3/envs/design-baseliness/lib/python3.7/logging/__init__.py", line 1028, in emit
    stream.write(msg + self.terminator)
ValueError: I/O operation on closed file.
Call stack:
  File "design_baselines/diff_multi/trainer_amend_multi.py", line 1099, in <module>
    device=device,
  File "design_baselines/diff_multi/trainer_amend_multi.py", line 489, in run_training
    limit_test_batches=0,
  File "/nethome/wmu30/anaconda3/envs/design-baseliness/lib/python3.7/site-packages/pytorch_lightning/utilities/argparse.py", line 339, in insert_env_defaults
    return fn(self, **kwargs)
  File "/nethome/wmu30/anaconda3/envs/design-baseliness/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 606, in __init__
    self._setup_on_init(num_sanity_val_steps)
  File "/nethome/wmu30/anaconda3/envs/design-baseliness/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 687, in _setup_on_init
    self._log_device_info()
  File "/nethome/wmu30/anaconda3/envs/design-baseliness/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 1811, in _log_device_info
    rank_zero_info(f"HPU available: {_HPU_AVAILABLE}, using: {num_hpus} HPUs")
  File "/nethome/wmu30/anaconda3/envs/design-baseliness/lib/python3.7/site-packages/pytorch_lightning/utilities/rank_zero.py", line 32, in wrapped_fn
    return fn(*args, **kwargs)
  File "/nethome/wmu30/anaconda3/envs/design-baseliness/lib/python3.7/site-packages/pytorch_lightning/utilities/rank_zero.py", line 75, in rank_zero_info
    _info(*args, stacklevel=stacklevel, **kwargs)
  File "/nethome/wmu30/anaconda3/envs/design-baseliness/lib/python3.7/site-packages/pytorch_lightning/utilities/rank_zero.py", line 57, in _info
    log.info(*args, **kwargs)
Message: 'HPU available: False, using: 0 HPUs'
Arguments: ()
--- Logging error ---
Traceback (most recent call last):
  File "/nethome/wmu30/anaconda3/envs/design-baseliness/lib/python3.7/logging/__init__.py", line 1028, in emit
    stream.write(msg + self.terminator)
ValueError: I/O operation on closed file.
Call stack:
  File "design_baselines/diff_multi/trainer_amend_multi.py", line 1099, in <module>
    device=device,
  File "design_baselines/diff_multi/trainer_amend_multi.py", line 489, in run_training
    limit_test_batches=0,
  File "/nethome/wmu30/anaconda3/envs/design-baseliness/lib/python3.7/site-packages/pytorch_lightning/utilities/argparse.py", line 339, in insert_env_defaults
    return fn(self, **kwargs)
  File "/nethome/wmu30/anaconda3/envs/design-baseliness/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 627, in __init__
    fast_dev_run,
  File "/nethome/wmu30/anaconda3/envs/design-baseliness/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 673, in _init_debugging_flags
    self.limit_val_batches = _determine_batch_limits(limit_val_batches, "limit_val_batches")
  File "/nethome/wmu30/anaconda3/envs/design-baseliness/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 2875, in _determine_batch_limits
    rank_zero_info(f"`Trainer({name}=1.0)` was configured so {message}.")
  File "/nethome/wmu30/anaconda3/envs/design-baseliness/lib/python3.7/site-packages/pytorch_lightning/utilities/rank_zero.py", line 32, in wrapped_fn
    return fn(*args, **kwargs)
  File "/nethome/wmu30/anaconda3/envs/design-baseliness/lib/python3.7/site-packages/pytorch_lightning/utilities/rank_zero.py", line 75, in rank_zero_info
    _info(*args, stacklevel=stacklevel, **kwargs)
  File "/nethome/wmu30/anaconda3/envs/design-baseliness/lib/python3.7/site-packages/pytorch_lightning/utilities/rank_zero.py", line 57, in _info
    log.info(*args, **kwargs)
Message: '`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..'
Arguments: ()
Epoch 0:   0%|                                                                                           | 0/79 [00:00<?, ?it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/nethome/wmu30/anaconda3/envs/design-baseliness/lib/python3.7/logging/__init__.py", line 1028, in emit
    stream.write(msg + self.terminator)
ValueError: I/O operation on closed file.
Call stack:
  File "design_baselines/diff_multi/trainer_amend_multi.py", line 1099, in <module>
    device=device,
  File "design_baselines/diff_multi/trainer_amend_multi.py", line 505, in run_training
    trainer.fit(model, data_module)
  File "/nethome/wmu30/anaconda3/envs/design-baseliness/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 771, in fit
    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path
  File "/nethome/wmu30/anaconda3/envs/design-baseliness/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 723, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/nethome/wmu30/anaconda3/envs/design-baseliness/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 811, in _fit_impl
    results = self._run(model, ckpt_path=self.ckpt_path)
  File "/nethome/wmu30/anaconda3/envs/design-baseliness/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 1217, in _run
    self.strategy.setup(self)
  File "/nethome/wmu30/anaconda3/envs/design-baseliness/lib/python3.7/site-packages/pytorch_lightning/strategies/single_device.py", line 72, in setup
    super().setup(trainer)
  File "/nethome/wmu30/anaconda3/envs/design-baseliness/lib/python3.7/site-packages/pytorch_lightning/strategies/strategy.py", line 138, in setup
    self.accelerator.setup(trainer)
  File "/nethome/wmu30/anaconda3/envs/design-baseliness/lib/python3.7/site-packages/pytorch_lightning/accelerators/gpu.py", line 47, in setup
    self.set_nvidia_flags(trainer.local_rank)
  File "/nethome/wmu30/anaconda3/envs/design-baseliness/lib/python3.7/site-packages/pytorch_lightning/accelerators/gpu.py", line 57, in set_nvidia_flags
    _log.info(f"LOCAL_RANK: {local_rank} - CUDA_VISIBLE_DEVICES: [{devices}]")
Message: 'LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]'
Arguments: ()
--- Logging error ---
Traceback (most recent call last):
  File "/nethome/wmu30/anaconda3/envs/design-baseliness/lib/python3.7/logging/__init__.py", line 1028, in emit
    stream.write(msg + self.terminator)
ValueError: I/O operation on closed file.
Call stack:
  File "design_baselines/diff_multi/trainer_amend_multi.py", line 1099, in <module>
    device=device,
  File "design_baselines/diff_multi/trainer_amend_multi.py", line 505, in run_training
    trainer.fit(model, data_module)
  File "/nethome/wmu30/anaconda3/envs/design-baseliness/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 771, in fit
    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path
  File "/nethome/wmu30/anaconda3/envs/design-baseliness/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 723, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/nethome/wmu30/anaconda3/envs/design-baseliness/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 811, in _fit_impl
    results = self._run(model, ckpt_path=self.ckpt_path)
  File "/nethome/wmu30/anaconda3/envs/design-baseliness/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 1221, in _run
    self._call_callback_hooks("on_fit_start")
  File "/nethome/wmu30/anaconda3/envs/design-baseliness/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 1636, in _call_callback_hooks
    fn(self, self.lightning_module, *args, **kwargs)
  File "/nethome/wmu30/anaconda3/envs/design-baseliness/lib/python3.7/site-packages/pytorch_lightning/callbacks/model_summary.py", line 63, in on_fit_start
    self.summarize(summary_data, total_parameters, trainable_parameters, model_size)
  File "/nethome/wmu30/anaconda3/envs/design-baseliness/lib/python3.7/site-packages/pytorch_lightning/callbacks/model_summary.py", line 73, in summarize
    log.info("\n" + summary_table)
Message: '\n  | Name            | Type                  | Params\n----------------------------------------------------------\n0 | score_estimator | MLP                   | 2.2 M \n1 | inf_sde         | VariancePreservingSDE | 1     \n2 | gen_sde         | ScorePluginReverseSDE | 2.2 M \n----------------------------------------------------------\n2.2 M     Trainable params\n1         Non-trainable params\n2.2 M     Total params\n8.667     Total estimated model params size (MB)'

Epoch 1:  76%|██████████████▍    | 60/79 [00:01<00:00, 45.70it/s, loss=16.1, v_num=mte5, train_loss=16.50, elbo_estimator=-60.9]







Epoch 8:  76%|██████████████▍    | 60/79 [00:01<00:00, 43.67it/s, loss=13.2, v_num=mte5, train_loss=12.40, elbo_estimator=-52.1]





Epoch 14:  76%|█████████████▋    | 60/79 [00:01<00:00, 43.04it/s, loss=11.7, v_num=mte5, train_loss=11.40, elbo_estimator=-46.1]





Epoch 20:  76%|█████████████▋    | 60/79 [00:01<00:00, 40.43it/s, loss=12.1, v_num=mte5, train_loss=12.00, elbo_estimator=-45.8]





Epoch 26:  76%|█████████████▋    | 60/79 [00:01<00:00, 41.57it/s, loss=11.9, v_num=mte5, train_loss=11.70, elbo_estimator=-45.8]




Epoch 31: 100%|████████████████████| 79/79 [00:02<00:00, 34.48it/s, loss=12, v_num=mte5, train_loss=12.00, elbo_estimator=-45.6]







Epoch 38:  76%|███████████████▏    | 60/79 [00:01<00:00, 41.86it/s, loss=12, v_num=mte5, train_loss=12.00, elbo_estimator=-45.4]



Epoch 42:  76%|█████████████▋    | 60/79 [00:01<00:00, 41.43it/s, loss=11.9, v_num=mte5, train_loss=13.00, elbo_estimator=-45.5]





Epoch 48:  76%|███████████████▏    | 60/79 [00:01<00:00, 41.24it/s, loss=12, v_num=mte5, train_loss=12.60, elbo_estimator=-46.0]





Epoch 54:  76%|███████████████▏    | 60/79 [00:01<00:00, 45.19it/s, loss=12, v_num=mte5, train_loss=12.00, elbo_estimator=-46.1]







Epoch 61:  76%|█████████████▋    | 60/79 [00:01<00:00, 43.87it/s, loss=11.8, v_num=mte5, train_loss=11.70, elbo_estimator=-46.0]






Epoch 67:  76%|█████████████▋    | 60/79 [00:01<00:00, 45.25it/s, loss=11.9, v_num=mte5, train_loss=11.50, elbo_estimator=-45.9]







Epoch 75:  76%|█████████████▋    | 60/79 [00:01<00:00, 43.88it/s, loss=11.7, v_num=mte5, train_loss=12.00, elbo_estimator=-46.4]





Epoch 81:  76%|█████████████▋    | 60/79 [00:01<00:00, 44.71it/s, loss=11.8, v_num=mte5, train_loss=11.50, elbo_estimator=-46.1]





Epoch 86:  76%|█████████████▋    | 60/79 [00:01<00:00, 42.10it/s, loss=11.9, v_num=mte5, train_loss=11.70, elbo_estimator=-46.2]






Epoch 93:  76%|█████████████▋    | 60/79 [00:01<00:00, 42.31it/s, loss=11.9, v_num=mte5, train_loss=11.40, elbo_estimator=-46.1]






Epoch 100:  76%|████████████▉    | 60/79 [00:01<00:00, 43.10it/s, loss=11.9, v_num=mte5, train_loss=11.80, elbo_estimator=-46.3]





Epoch 106:  76%|████████████▉    | 60/79 [00:01<00:00, 42.95it/s, loss=11.9, v_num=mte5, train_loss=11.70, elbo_estimator=-46.6]




Epoch 111:  76%|████████████▉    | 60/79 [00:01<00:00, 40.53it/s, loss=11.9, v_num=mte5, train_loss=11.10, elbo_estimator=-46.2]




Epoch 116:  76%|██████████████▍    | 60/79 [00:01<00:00, 41.55it/s, loss=12, v_num=mte5, train_loss=11.80, elbo_estimator=-46.4]





Epoch 121:  76%|████████████▉    | 60/79 [00:01<00:00, 44.20it/s, loss=11.7, v_num=mte5, train_loss=12.10, elbo_estimator=-46.6]







Epoch 129:  76%|████████████▉    | 60/79 [00:01<00:00, 45.62it/s, loss=11.9, v_num=mte5, train_loss=11.50, elbo_estimator=-46.7]






Epoch 136:  76%|████████████▉    | 60/79 [00:01<00:00, 44.69it/s, loss=11.9, v_num=mte5, train_loss=12.40, elbo_estimator=-46.6]





Epoch 142:  76%|████████████▉    | 60/79 [00:01<00:00, 42.71it/s, loss=11.8, v_num=mte5, train_loss=11.40, elbo_estimator=-46.9]






Epoch 149:  76%|████████████▉    | 60/79 [00:01<00:00, 42.32it/s, loss=11.7, v_num=mte5, train_loss=11.70, elbo_estimator=-46.4]





Epoch 155:  76%|████████████▉    | 60/79 [00:01<00:00, 42.62it/s, loss=11.6, v_num=mte5, train_loss=11.70, elbo_estimator=-46.4]




Epoch 159:  76%|████████████▉    | 60/79 [00:01<00:00, 41.43it/s, loss=11.8, v_num=mte5, train_loss=12.20, elbo_estimator=-46.5]





Epoch 164:  76%|████████████▉    | 60/79 [00:01<00:00, 41.29it/s, loss=11.6, v_num=mte5, train_loss=11.50, elbo_estimator=-46.8]






Epoch 171:  76%|████████████▉    | 60/79 [00:01<00:00, 43.16it/s, loss=11.7, v_num=mte5, train_loss=11.20, elbo_estimator=-46.5]






Epoch 178:  76%|████████████▉    | 60/79 [00:01<00:00, 44.94it/s, loss=11.6, v_num=mte5, train_loss=11.80, elbo_estimator=-46.3]





Epoch 185:  76%|████████████▉    | 60/79 [00:01<00:00, 42.11it/s, loss=11.6, v_num=mte5, train_loss=11.60, elbo_estimator=-46.9]






Epoch 191:  76%|████████████▉    | 60/79 [00:01<00:00, 45.33it/s, loss=11.7, v_num=mte5, train_loss=12.10, elbo_estimator=-47.7]






Epoch 197:  76%|████████████▉    | 60/79 [00:01<00:00, 42.99it/s, loss=11.5, v_num=mte5, train_loss=11.90, elbo_estimator=-46.9]





Epoch 202:  76%|████████████▉    | 60/79 [00:01<00:00, 40.13it/s, loss=11.5, v_num=mte5, train_loss=11.20, elbo_estimator=-47.2]






Epoch 209:  76%|████████████▉    | 60/79 [00:01<00:00, 44.57it/s, loss=11.6, v_num=mte5, train_loss=11.30, elbo_estimator=-47.4]






Epoch 216:  76%|████████████▉    | 60/79 [00:01<00:00, 43.81it/s, loss=11.5, v_num=mte5, train_loss=11.50, elbo_estimator=-47.6]





Epoch 222:  76%|▊| 60/79 [00:01<00:00, 41.59it/s, loss=11.4, v_num=mte5, train_loss=11.20, elbo_estimator=-




Epoch 227:  76%|▊| 60/79 [00:01<00:00, 39.68it/s, loss=11.5, v_num=mte5, train_loss=11.30, elbo_estimator=-





Epoch 233:  76%|▊| 60/79 [00:01<00:00, 42.79it/s, loss=11.4, v_num=mte5, train_loss=11.30, elbo_estimator=-











Epoch 244:  76%|▊| 60/79 [00:01<00:00, 42.68it/s, loss=11.4, v_num=mte5, train_loss=11.30, elbo_estimator=-





Epoch 249:  76%|▊| 60/79 [00:01<00:00, 41.14it/s, loss=11.4, v_num=mte5, train_loss=11.30, elbo_estimator=-








Epoch 257:  76%|▊| 60/79 [00:01<00:00, 46.53it/s, loss=11.4, v_num=mte5, train_loss=11.60, elbo_estimator=-






Epoch 265:  76%|▊| 60/79 [00:01<00:00, 44.72it/s, loss=11.3, v_num=mte5, train_loss=11.50, elbo_estimator=-




Epoch 271:  76%|▊| 60/79 [00:01<00:00, 36.78it/s, loss=11.2, v_num=mte5, train_loss=10.60, elbo_estimator=-






Epoch 277:  76%|▊| 60/79 [00:01<00:00, 43.35it/s, loss=11.2, v_num=mte5, train_loss=11.20, elbo_estimator=-







Epoch 286:  76%|▊| 60/79 [00:01<00:00, 44.13it/s, loss=11.2, v_num=mte5, train_loss=11.20, elbo_estimator=-




Epoch 291:  76%|▊| 60/79 [00:01<00:00, 42.19it/s, loss=11.3, v_num=mte5, train_loss=11.70, elbo_estimator=-






Epoch 298:  76%|▊| 60/79 [00:01<00:00, 43.61it/s, loss=11.3, v_num=mte5, train_loss=11.40, elbo_estimator=-





Epoch 304:  76%|▊| 60/79 [00:01<00:00, 42.73it/s, loss=11.3, v_num=mte5, train_loss=11.00, elbo_estimator=-








Epoch 312:  76%|▊| 60/79 [00:01<00:00, 46.04it/s, loss=11.3, v_num=mte5, train_loss=11.10, elbo_estimator=-






Epoch 319:  76%|▊| 60/79 [00:01<00:00, 43.53it/s, loss=11.1, v_num=mte5, train_loss=11.30, elbo_estimator=-






Epoch 326:  76%|▊| 60/79 [00:01<00:00, 41.99it/s, loss=11.2, v_num=mte5, train_loss=10.80, elbo_estimator=-



Epoch 330:  76%|▊| 60/79 [00:02<00:00, 29.57it/s, loss=11, v_num=mte5, train_loss=11.20, elbo_estimator=-51





Epoch 335:  76%|▊| 60/79 [00:01<00:00, 41.40it/s, loss=11.2, v_num=mte5, train_loss=11.40, elbo_estimator=-





Epoch 340:  76%|▊| 60/79 [00:01<00:00, 40.52it/s, loss=11.2, v_num=mte5, train_loss=11.30, elbo_estimator=-




Epoch 344:  76%|▊| 60/79 [00:01<00:00, 42.06it/s, loss=11, v_num=mte5, train_loss=11.00, elbo_estimator=-51





Epoch 349:  76%|▊| 60/79 [00:01<00:00, 47.73it/s, loss=10.9, v_num=mte5, train_loss=11.00, elbo_estimator=-





Epoch 355:  76%|▊| 60/79 [00:01<00:00, 43.92it/s, loss=11.1, v_num=mte5, train_loss=11.30, elbo_estimator=-





Epoch 360:  76%|▊| 60/79 [00:01<00:00, 38.15it/s, loss=11, v_num=mte5, train_loss=10.60, elbo_estimator=-51




Epoch 364:  76%|▊| 60/79 [00:01<00:00, 37.71it/s, loss=11.1, v_num=mte5, train_loss=11.10, elbo_estimator=-




Epoch 369:  76%|▊| 60/79 [00:01<00:00, 44.10it/s, loss=11.1, v_num=mte5, train_loss=11.60, elbo_estimator=-




Epoch 374:  76%|▊| 60/79 [00:01<00:00, 44.30it/s, loss=11, v_num=mte5, train_loss=11.30, elbo_estimator=-53





Epoch 379:  76%|▊| 60/79 [00:01<00:00, 39.80it/s, loss=10.9, v_num=mte5, train_loss=10.40, elbo_estimator=-






Epoch 385:  76%|▊| 60/79 [00:01<00:00, 46.84it/s, loss=11, v_num=mte5, train_loss=10.50, elbo_estimator=-53




Epoch 390:  76%|▊| 60/79 [00:01<00:00, 42.79it/s, loss=11, v_num=mte5, train_loss=11.10, elbo_estimator=-54





Epoch 396:  76%|▊| 60/79 [00:01<00:00, 43.93it/s, loss=10.9, v_num=mte5, train_loss=10.80, elbo_estimator=-




Epoch 401:  76%|▊| 60/79 [00:01<00:00, 45.06it/s, loss=11, v_num=mte5, train_loss=11.10, elbo_estimator=-54





Epoch 406:  76%|▊| 60/79 [00:01<00:00, 40.18it/s, loss=10.8, v_num=mte5, train_loss=11.00, elbo_estimator=-





Epoch 411:  76%|▊| 60/79 [00:01<00:00, 43.71it/s, loss=10.9, v_num=mte5, train_loss=11.10, elbo_estimator=-






Epoch 418:  76%|▊| 60/79 [00:01<00:00, 38.42it/s, loss=10.9, v_num=mte5, train_loss=10.70, elbo_estimator=-



Epoch 421:  76%|▊| 60/79 [00:01<00:00, 38.19it/s, loss=10.8, v_num=mte5, train_loss=11.30, elbo_estimator=-




Epoch 426:  76%|▊| 60/79 [00:01<00:00, 43.94it/s, loss=10.8, v_num=mte5, train_loss=10.40, elbo_estimator=-




Epoch 431:  76%|▊| 60/79 [00:01<00:00, 45.03it/s, loss=11, v_num=mte5, train_loss=10.50, elbo_estimator=-56




Epoch 436:  76%|▊| 60/79 [00:01<00:00, 41.46it/s, loss=10.9, v_num=mte5, train_loss=10.60, elbo_estimator=-




Epoch 440:  76%|▊| 60/79 [00:01<00:00, 39.51it/s, loss=11, v_num=mte5, train_loss=11.10, elbo_estimator=-56








Epoch 448:  76%|▊| 60/79 [00:01<00:00, 41.32it/s, loss=10.8, v_num=mte5, train_loss=11.10, elbo_estimator=-





Epoch 453:  76%|▊| 60/79 [00:01<00:00, 38.74it/s, loss=10.9, v_num=mte5, train_loss=11.10, elbo_estimator=-




Epoch 457:  76%|▊| 60/79 [00:01<00:00, 37.63it/s, loss=10.8, v_num=mte5, train_loss=11.30, elbo_estimator=-





Epoch 462:  76%|▊| 60/79 [00:01<00:00, 44.29it/s, loss=10.9, v_num=mte5, train_loss=10.60, elbo_estimator=-











Epoch 472:  76%|▊| 60/79 [00:01<00:00, 40.23it/s, loss=10.8, v_num=mte5, train_loss=11.00, elbo_estimator=-






Epoch 478:  76%|▊| 60/79 [00:01<00:00, 39.23it/s, loss=10.9, v_num=mte5, train_loss=11.30, elbo_estimator=-




Epoch 482:  76%|▊| 60/79 [00:01<00:00, 39.23it/s, loss=10.8, v_num=mte5, train_loss=10.10, elbo_estimator=-




Epoch 487:  76%|▊| 60/79 [00:01<00:00, 38.49it/s, loss=10.9, v_num=mte5, train_loss=10.70, elbo_estimator=-




Epoch 491:  76%|▊| 60/79 [00:01<00:00, 40.63it/s, loss=10.8, v_num=mte5, train_loss=11.40, elbo_estimator=-



Epoch 494:  76%|▊| 60/79 [00:01<00:00, 40.36it/s, loss=10.9, v_num=mte5, train_loss=11.10, elbo_estimator=-




Epoch 499:  76%|▊| 60/79 [00:01<00:00, 45.00it/s, loss=10.8, v_num=mte5, train_loss=10.70, elbo_estimator=-




Epoch 503:  76%|▊| 60/79 [00:01<00:00, 42.21it/s, loss=10.8, v_num=mte5, train_loss=10.60, elbo_estimator=-




Epoch 508:  76%|▊| 60/79 [00:01<00:00, 42.78it/s, loss=10.8, v_num=mte5, train_loss=10.90, elbo_estimator=-




Epoch 513:  76%|▊| 60/79 [00:01<00:00, 40.97it/s, loss=10.8, v_num=mte5, train_loss=10.10, elbo_estimator=-




Epoch 518:  76%|▊| 60/79 [00:01<00:00, 45.05it/s, loss=10.7, v_num=mte5, train_loss=11.30, elbo_estimator=-




Epoch 522:  76%|▊| 60/79 [00:01<00:00, 39.15it/s, loss=10.7, v_num=mte5, train_loss=10.50, elbo_estimator=-




Epoch 527:  76%|▊| 60/79 [00:01<00:00, 41.05it/s, loss=10.7, v_num=mte5, train_loss=10.60, elbo_estimator=-





Epoch 533:  76%|▊| 60/79 [00:01<00:00, 41.69it/s, loss=10.7, v_num=mte5, train_loss=10.70, elbo_estimator=-




Epoch 537:  76%|▊| 60/79 [00:01<00:00, 34.98it/s, loss=10.6, v_num=mte5, train_loss=9.750, elbo_estimator=-




Epoch 541:  76%|▊| 60/79 [00:01<00:00, 39.20it/s, loss=10.6, v_num=mte5, train_loss=11.30, elbo_estimator=-




Epoch 545:  76%|▊| 60/79 [00:01<00:00, 37.93it/s, loss=10.8, v_num=mte5, train_loss=11.00, elbo_estimator=-



Epoch 549:  76%|▊| 60/79 [00:01<00:00, 43.58it/s, loss=10.7, v_num=mte5, train_loss=10.60, elbo_estimator=-




Epoch 553:  76%|▊| 60/79 [00:01<00:00, 40.90it/s, loss=10.6, v_num=mte5, train_loss=10.30, elbo_estimator=-



Epoch 556:  76%|▊| 60/79 [00:01<00:00, 39.98it/s, loss=10.7, v_num=mte5, train_loss=10.70, elbo_estimator=-




Epoch 560: 100%|█| 79/79 [00:02<00:00, 32.44it/s, loss=10.6, v_num=mte5, train_loss=10.30, elbo_estimator=-





Epoch 565:  76%|▊| 60/79 [00:01<00:00, 41.98it/s, loss=10.6, v_num=mte5, train_loss=10.40, elbo_estimator=-




Epoch 570:  76%|▊| 60/79 [00:01<00:00, 41.92it/s, loss=10.7, v_num=mte5, train_loss=11.10, elbo_estimator=-





Epoch 575:  76%|▊| 60/79 [00:01<00:00, 39.41it/s, loss=10.7, v_num=mte5, train_loss=10.60, elbo_estimator=-




Epoch 579:  76%|▊| 60/79 [00:01<00:00, 39.58it/s, loss=10.7, v_num=mte5, train_loss=10.70, elbo_estimator=-




Epoch 583:  76%|▊| 60/79 [00:01<00:00, 35.06it/s, loss=10.6, v_num=mte5, train_loss=10.70, elbo_estimator=-




Epoch 587:  76%|▊| 60/79 [00:01<00:00, 46.48it/s, loss=10.6, v_num=mte5, train_loss=10.60, elbo_estimator=-





Epoch 592:  76%|▊| 60/79 [00:01<00:00, 38.45it/s, loss=10.4, v_num=mte5, train_loss=10.60, elbo_estimator=-





Epoch 597:  76%|▊| 60/79 [00:01<00:00, 46.02it/s, loss=10.6, v_num=mte5, train_loss=10.90, elbo_estimator=-




Epoch 601:  76%|▊| 60/79 [00:01<00:00, 40.52it/s, loss=10.5, v_num=mte5, train_loss=10.50, elbo_estimator=-




Epoch 605:  76%|▊| 60/79 [00:01<00:00, 38.07it/s, loss=10.6, v_num=mte5, train_loss=10.60, elbo_estimator=-




Epoch 609:  76%|▊| 60/79 [00:01<00:00, 41.64it/s, loss=10.4, v_num=mte5, train_loss=10.20, elbo_estimator=-




Epoch 614:  76%|▊| 60/79 [00:01<00:00, 40.31it/s, loss=10.4, v_num=mte5, train_loss=10.50, elbo_estimator=-




Epoch 618:  76%|▊| 60/79 [00:01<00:00, 43.73it/s, loss=10.5, v_num=mte5, train_loss=10.30, elbo_estimator=-





Epoch 623:  76%|▊| 60/79 [00:01<00:00, 40.85it/s, loss=10.4, v_num=mte5, train_loss=10.20, elbo_estimator=-




Epoch 628:  76%|▊| 60/79 [00:01<00:00, 39.42it/s, loss=10.5, v_num=mte5, train_loss=10.20, elbo_estimator=-




Epoch 633:  76%|▊| 60/79 [00:01<00:00, 38.51it/s, loss=10.4, v_num=mte5, train_loss=10.70, elbo_estimator=-





Epoch 638:  76%|▊| 60/79 [00:01<00:00, 41.66it/s, loss=10.4, v_num=mte5, train_loss=11.50, elbo_estimator=-




Epoch 642: 100%|█| 79/79 [00:02<00:00, 33.24it/s, loss=10.4, v_num=mte5, train_loss=10.00, elbo_estimator=-





Epoch 647:  76%|▊| 60/79 [00:01<00:00, 46.39it/s, loss=10.5, v_num=mte5, train_loss=10.60, elbo_estimator=-






Epoch 653:  76%|▊| 60/79 [00:01<00:00, 45.09it/s, loss=10.4, v_num=mte5, train_loss=9.860, elbo_estimator=-




Epoch 657:  76%|▊| 60/79 [00:01<00:00, 42.05it/s, loss=10.5, v_num=mte5, train_loss=10.30, elbo_estimator=-





Epoch 662:  76%|▊| 60/79 [00:01<00:00, 41.66it/s, loss=10.2, v_num=mte5, train_loss=9.730, elbo_estimator=-





Epoch 667:  76%|▊| 60/79 [00:01<00:00, 40.70it/s, loss=10.4, v_num=mte5, train_loss=10.40, elbo_estimator=-




Epoch 671:  76%|▊| 60/79 [00:01<00:00, 41.56it/s, loss=10.4, v_num=mte5, train_loss=10.80, elbo_estimator=-




Epoch 675:  76%|▊| 60/79 [00:01<00:00, 39.81it/s, loss=10.4, v_num=mte5, train_loss=10.00, elbo_estimator=-







Epoch 683:  76%|▊| 60/79 [00:01<00:00, 42.62it/s, loss=10.4, v_num=mte5, train_loss=10.00, elbo_estimator=-







Epoch 691:  76%|▊| 60/79 [00:01<00:00, 45.04it/s, loss=10.3, v_num=mte5, train_loss=10.30, elbo_estimator=-






Epoch 698:  76%|▊| 60/79 [00:01<00:00, 46.01it/s, loss=10.2, v_num=mte5, train_loss=9.630, elbo_estimator=-




Epoch 704:  76%|▊| 60/79 [00:01<00:00, 46.20it/s, loss=10.2, v_num=mte5, train_loss=10.60, elbo_estimator=-






Epoch 712:  76%|▊| 60/79 [00:01<00:00, 44.26it/s, loss=10.4, v_num=mte5, train_loss=9.990, elbo_estimator=-







Epoch 721:  76%|▊| 60/79 [00:01<00:00, 43.98it/s, loss=10.4, v_num=mte5, train_loss=10.20, elbo_estimator=-







Epoch 729:  76%|▊| 60/79 [00:01<00:00, 42.11it/s, loss=10.2, v_num=mte5, train_loss=9.920, elbo_estimator=-








Epoch 738:  76%|▊| 60/79 [00:01<00:00, 43.81it/s, loss=10.3, v_num=mte5, train_loss=10.00, elbo_estimator=-









Epoch 748:  76%|▊| 60/79 [00:01<00:00, 50.55it/s, loss=10.3, v_num=mte5, train_loss=10.70, elbo_estimator=-






Epoch 755:  76%|▊| 60/79 [00:01<00:00, 45.08it/s, loss=10.3, v_num=mte5, train_loss=10.50, elbo_estimator=-









Epoch 765:  76%|▊| 60/79 [00:01<00:00, 48.41it/s, loss=10.3, v_num=mte5, train_loss=10.40, elbo_estimator=-








Epoch 775:  76%|▊| 60/79 [00:01<00:00, 46.37it/s, loss=10.2, v_num=mte5, train_loss=10.10, elbo_estimator=-







Epoch 784:  76%|▊| 60/79 [00:01<00:00, 47.24it/s, loss=10.3, v_num=mte5, train_loss=10.20, elbo_estimator=-







Epoch 792:  76%|▊| 60/79 [00:01<00:00, 44.84it/s, loss=10.1, v_num=mte5, train_loss=10.20, elbo_estimator=-





Epoch 799:  76%|▊| 60/79 [00:01<00:00, 44.49it/s, loss=10.2, v_num=mte5, train_loss=10.60, elbo_estimator=-






Epoch 806:  76%|▊| 60/79 [00:01<00:00, 43.69it/s, loss=10.1, v_num=mte5, train_loss=10.20, elbo_estimator=-






Epoch 814:  76%|▊| 60/79 [00:01<00:00, 45.58it/s, loss=10.2, v_num=mte5, train_loss=9.840, elbo_esti






Epoch 821:  76%|▊| 60/79 [00:01<00:00, 45.77it/s, loss=10.1, v_num=mte5, train_loss=9.610, elbo_esti







Epoch 830:  76%|▊| 60/79 [00:01<00:00, 44.74it/s, loss=10.1, v_num=mte5, train_loss=9.280, elbo_esti






Epoch 837:  76%|▊| 60/79 [00:01<00:00, 49.54it/s, loss=10.2, v_num=mte5, train_loss=10.10, elbo_esti








Epoch 847: 100%|█| 79/79 [00:02<00:00, 37.25it/s, loss=10, v_num=mte5, train_loss=10.00, elbo_estima





Epoch 853:  76%|▊| 60/79 [00:01<00:00, 42.76it/s, loss=10.1, v_num=mte5, train_loss=10.10, elbo_esti









Epoch 863:  76%|▊| 60/79 [00:01<00:00, 45.95it/s, loss=10, v_num=mte5, train_loss=9.600, elbo_estima






Epoch 870:  76%|▊| 60/79 [00:01<00:00, 43.47it/s, loss=10.1, v_num=mte5, train_loss=10.60, elbo_esti








Epoch 878:  76%|▊| 60/79 [00:01<00:00, 47.47it/s, loss=10.1, v_num=mte5, train_loss=9.630, elbo_esti








Epoch 888:  76%|▊| 60/79 [00:01<00:00, 46.91it/s, loss=10.1, v_num=mte5, train_loss=10.10, elbo_esti






Epoch 895:  76%|▊| 60/79 [00:01<00:00, 41.14it/s, loss=9.88, v_num=mte5, train_loss=9.010, elbo_esti





Epoch 901:  76%|▊| 60/79 [00:01<00:00, 44.43it/s, loss=10.1, v_num=mte5, train_loss=9.920, elbo_esti






Epoch 908:  76%|▊| 60/79 [00:01<00:00, 42.30it/s, loss=10.1, v_num=mte5, train_loss=10.70, elbo_esti







Epoch 916:  76%|▊| 60/79 [00:01<00:00, 45.23it/s, loss=9.89, v_num=mte5, train_loss=10.20, elbo_esti







Epoch 924:  76%|████████████████▋     | 60/79 [00:01<00:00, 44.87it/s, loss=9.96, v_num=mte5, train_loss=9.690, elbo_estimator=-79.1]






Epoch 931:  76%|████████████████▋     | 60/79 [00:01<00:00, 44.52it/s, loss=10.1, v_num=mte5, train_loss=10.00, elbo_estimator=-76.9]








Epoch 940:  76%|████████████████▋     | 60/79 [00:01<00:00, 45.56it/s, loss=9.84, v_num=mte5, train_loss=9.600, elbo_estimator=-78.9]





Epoch 945:  76%|████████████████▋     | 60/79 [00:01<00:00, 42.52it/s, loss=9.96, v_num=mte5, train_loss=10.20, elbo_estimator=-77.7]








Epoch 956:  76%|██████████████████▏     | 60/79 [00:01<00:00, 46.14it/s, loss=10, v_num=mte5, train_loss=11.00, elbo_estimator=-76.2]





Epoch 962:  76%|████████████████▋     | 60/79 [00:01<00:00, 46.61it/s, loss=9.91, v_num=mte5, train_loss=10.30, elbo_estimator=-78.8]





Epoch 968:  76%|████████████████▋     | 60/79 [00:01<00:00, 42.43it/s, loss=9.77, v_num=mte5, train_loss=9.460, elbo_estimator=-80.4]




Epoch 974:  76%|████████████████▋     | 60/79 [00:01<00:00, 41.31it/s, loss=9.87, v_num=mte5, train_loss=9.980, elbo_estimator=-80.0]


Epoch 977: 100%|██████████████████████| 79/79 [00:02<00:00, 34.45it/s, loss=9.81, v_num=mte5, train_loss=7.520, elbo_estimator=-75.3]




Epoch 981:  76%|████████████████▋     | 60/79 [00:01<00:00, 39.94it/s, loss=9.86, v_num=mte5, train_loss=10.10, elbo_estimator=-84.6]




Epoch 986:  76%|████████████████▋     | 60/79 [00:01<00:00, 42.51it/s, loss=9.79, v_num=mte5, train_loss=9.730, elbo_estimator=-79.7]



Epoch 990:  76%|████████████████▋     | 60/79 [00:01<00:00, 39.78it/s, loss=9.91, v_num=mte5, train_loss=9.760, elbo_estimator=-80.0]



Epoch 994:  76%|████████████████▋     | 60/79 [00:01<00:00, 38.76it/s, loss=9.91, v_num=mte5, train_loss=9.470, elbo_estimator=-82.1]







Epoch 999: 100%|██████████████████████| 79/79 [00:02<00:00, 33.69it/s, loss=9.71, v_num=mte5, train_loss=7.300, elbo_estimator=-80.2]