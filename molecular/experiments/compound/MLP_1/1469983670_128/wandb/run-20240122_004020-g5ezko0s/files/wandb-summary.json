{"train_loss": 0.12577682733535767, "grad_2.0_norm/mlp.main.0.weight_step": 0.2506999969482422, "grad_2.0_norm/mlp.main.0.bias_step": 0.04650000110268593, "grad_2.0_norm/mlp.main.2.weight_step": 0.24959999322891235, "grad_2.0_norm/mlp.main.2.bias_step": 0.016899999231100082, "grad_2.0_norm/mlp.main.4.weight_step": 0.3513000011444092, "grad_2.0_norm/mlp.main.4.bias_step": 0.010999999940395355, "grad_2.0_norm/mlp.main.6.weight_step": 1.2253999710083008, "grad_2.0_norm/mlp.main.6.bias_step": 0.11180000007152557, "grad_2.0_norm_total_step": 1.3286000490188599, "epoch": 199, "trainer/global_step": 14199, "_timestamp": 1705902607.9784245, "_runtime": 587.7534635066986, "_step": 683, "val_loss": 0.5603501796722412, "grad_2.0_norm/mlp.main.0.weight_epoch": 0.168976292014122, "grad_2.0_norm/mlp.main.0.bias_epoch": 0.030559729784727097, "grad_2.0_norm/mlp.main.2.weight_epoch": 0.1891697645187378, "grad_2.0_norm/mlp.main.2.bias_epoch": 0.01256648637354374, "grad_2.0_norm/mlp.main.4.weight_epoch": 0.2959556579589844, "grad_2.0_norm/mlp.main.4.bias_epoch": 0.00914399977773428, "grad_2.0_norm/mlp.main.6.weight_epoch": 1.4746572971343994, "grad_2.0_norm/mlp.main.6.bias_epoch": 0.08880408853292465, "grad_2.0_norm_total_epoch": 1.5336885452270508, "_wandb": {"runtime": 587}}