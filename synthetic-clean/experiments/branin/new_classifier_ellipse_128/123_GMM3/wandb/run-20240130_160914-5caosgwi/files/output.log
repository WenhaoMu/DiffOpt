('out_directory: '
 './experiments/branin/new_classifier_ellipse_128/123_GMM3/wandb/run-20240130_160914-5caosgwi/files')
shapesss (6040, 2) (1, 6040, 1)
shapesss (6040, 2) (6040, 1)
[8.40824839e-21 9.66923258e-20 1.11254525e-18 1.28087196e-17
 1.47931871e-16 1.70184561e-15 1.95155433e-14 2.24314893e-13
 2.57221530e-12 2.95893976e-11 3.40580609e-10 3.86106714e-09
 4.40428979e-08 4.98776984e-07 5.61496433e-06 6.32810815e-05
 7.38673042e-04 8.06684931e-03 9.10087297e-02 9.00116169e-01]
/nethome/wmu30/anaconda3/envs/design-baseliness/lib/python3.7/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py:53: LightningDeprecationWarning: Setting `max_steps = None` is deprecated in v1.5 and will no longer be supported in v1.7. Use `max_steps = -1` instead.
  "Setting `max_steps = None` is deprecated in v1.5 and will no longer be supported in v1.7."
/nethome/wmu30/anaconda3/envs/design-baseliness/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:97: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=20)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.
  f"Setting `Trainer(progress_bar_refresh_rate={progress_bar_refresh_rate})` is deprecated in v1.5 and"
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
Sanity Checking DataLoader 0:   0%|                                                                             | 0/2 [00:00<?, ?it/s]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]
  | Name    | Type                  | Params
--------------------------------------------------
0 | mlp     | MLP                   | 2.1 M
1 | inf_sde | VariancePreservingSDE | 1
--------------------------------------------------
2.1 M     Trainable params
1         Non-trainable params
2.1 M     Total params
Epoch 0:  83%|███████████████████████████████████████▏       | 40/48 [00:01<00:00, 34.04it/s, loss=0.72, v_num=sgwi, train_loss=0.706]
Validation: 0it [00:00, ?it/s]
/nethome/wmu30/anaconda3/envs/design-baseliness/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py:1937: PossibleUserWarning: The number of training batches (43) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.














Epoch 15:  83%|████████████████████████▏    | 40/48 [00:01<00:00, 31.53it/s, loss=0.577, v_num=sgwi, train_loss=0.626, val_loss=0.503]












Epoch 30: 100%|█████████████████████████████| 48/48 [00:01<00:00, 24.05it/s, loss=0.569, v_num=sgwi, train_loss=0.487, val_loss=0.555]








Epoch 43:  83%|████████████████████████▏    | 40/48 [00:01<00:00, 32.57it/s, loss=0.586, v_num=sgwi, train_loss=0.503, val_loss=0.586]













Epoch 58:  83%|████████████████████████▏    | 40/48 [00:01<00:00, 31.16it/s, loss=0.557, v_num=sgwi, train_loss=0.477, val_loss=0.585]








Epoch 71: 100%|█████████████████████████████| 48/48 [00:02<00:00, 23.52it/s, loss=0.576, v_num=sgwi, train_loss=0.659, val_loss=0.570]









Epoch 85:  83%|████████████████████████▏    | 40/48 [00:01<00:00, 31.14it/s, loss=0.558, v_num=sgwi, train_loss=0.580, val_loss=0.565]


























Epoch 114:  83%|███████████████████████▎    | 40/48 [00:01<00:00, 34.20it/s, loss=0.558, v_num=sgwi, train_loss=0.674, val_loss=0.563]

















Epoch 139:  83%|███████████████████████▎    | 40/48 [00:01<00:00, 33.64it/s, loss=0.541, v_num=sgwi, train_loss=0.475, val_loss=0.639]

















Epoch 163:  83%|████████████████████████▏    | 40/48 [00:01<00:00, 32.31it/s, loss=0.58, v_num=sgwi, train_loss=0.673, val_loss=0.550]


































Epoch 198:  83%|███████████████████████▎    | 40/48 [00:01<00:00, 33.83it/s, loss=0.563, v_num=sgwi, train_loss=0.626, val_loss=0.523]



Epoch 202:  83%|███████████████████████▎    | 40/48 [00:01<00:00, 31.77it/s, loss=0.573, v_num=sgwi, train_loss=0.443, val_loss=0.495]















Epoch 222:  83%|███████████████████████▎    | 40/48 [00:01<00:00, 31.40it/s, loss=0.559, v_num=sgwi, train_loss=0.543, val_loss=0.541]





















Epoch 258:  83%|███████████████████████▎    | 40/48 [00:01<00:00, 34.87it/s, loss=0.564, v_num=sgwi, train_loss=0.585, val_loss=0.579]































Epoch 294:  83%|███████████████████████▎    | 40/48 [00:01<00:00, 35.18it/s, loss=0.567, v_num=sgwi, train_loss=0.557, val_loss=0.577]























Epoch 329:  83%|███████████████████████▎    | 40/48 [00:01<00:00, 30.84it/s, loss=0.558, v_num=sgwi, train_loss=0.492, val_loss=0.522]










Epoch 341:  83%|███████████████████████▎    | 40/48 [00:01<00:00, 32.29it/s, loss=0.565, v_num=sgwi, train_loss=0.566, val_loss=0.593]











Epoch 355:  83%|███████████████████████▎    | 40/48 [00:01<00:00, 30.53it/s, loss=0.578, v_num=sgwi, train_loss=0.600, val_loss=0.542]










Epoch 367:  83%|███████████████████████▎    | 40/48 [00:01<00:00, 29.24it/s, loss=0.521, v_num=sgwi, train_loss=0.459, val_loss=0.526]













Epoch 384:  83%|███████████████████████▎    | 40/48 [00:01<00:00, 30.12it/s, loss=0.562, v_num=sgwi, train_loss=0.472, val_loss=0.520]













Epoch 397:  83%|███████████████████████▎    | 40/48 [00:01<00:00, 33.91it/s, loss=0.548, v_num=sgwi, train_loss=0.650, val_loss=0.513]













Epoch 416:  83%|███████████████████████▎    | 40/48 [00:01<00:00, 33.73it/s, loss=0.565, v_num=sgwi, train_loss=0.605, val_loss=0.521]










Epoch 429:  83%|███████████████████████▎    | 40/48 [00:01<00:00, 34.43it/s, loss=0.565, v_num=sgwi, train_loss=0.661, val_loss=0.535]





































Epoch 472:  83%|███████████████████████▎    | 40/48 [00:01<00:00, 32.09it/s, loss=0.568, v_num=sgwi, train_loss=0.678, val_loss=0.526]

Epoch 477:  83%|███████████████████████▎    | 40/48 [00:01<00:00, 35.58it/s, loss=0.551, v_num=sgwi, train_loss=0.559, val_loss=0.547]

















Epoch 494:  83%|███████████████████████▎    | 40/48 [00:01<00:00, 29.23it/s, loss=0.514, v_num=sgwi, train_loss=0.569, val_loss=0.509]




























Epoch 530:  83%|███████████████████████▎    | 40/48 [00:01<00:00, 30.88it/s, loss=0.558, v_num=sgwi, train_loss=0.480, val_loss=0.540]

















Epoch 551:  83%|███████████████████████▎    | 40/48 [00:01<00:00, 33.22it/s, loss=0.569, v_num=sgwi, train_loss=0.526, val_loss=0.561]


















Epoch 574:  83%|███████████████████████▎    | 40/48 [00:01<00:00, 29.72it/s, loss=0.547, v_num=sgwi, train_loss=0.445, val_loss=0.466]

Epoch 583:  83%|███████████████████████▎    | 40/48 [00:01<00:00, 36.61it/s, loss=0.545, v_num=sgwi, train_loss=0.477, val_loss=0.513]


















Epoch 601:  83%|███████████████████████▎    | 40/48 [00:01<00:00, 33.39it/s, loss=0.573, v_num=sgwi, train_loss=0.554, val_loss=0.499]


Epoch 610:  83%|███████████████████████▎    | 40/48 [00:01<00:00, 35.15it/s, loss=0.553, v_num=sgwi, train_loss=0.525, val_loss=0.495]





Epoch 615:  83%|███████████████████████▎    | 40/48 [00:01<00:00, 32.40it/s, loss=0.583, v_num=sgwi, train_loss=0.466, val_loss=0.544]

















Epoch 642:  83%|████████████████████████▏    | 40/48 [00:01<00:00, 31.51it/s, loss=0.56, v_num=sgwi, train_loss=0.406, val_loss=0.609]


















Epoch 666:  83%|███████████████████████▎    | 40/48 [00:01<00:00, 31.23it/s, loss=0.559, v_num=sgwi, train_loss=0.633, val_loss=0.570]







Epoch 677:  83%|███████████████████████▎    | 40/48 [00:01<00:00, 33.76it/s, loss=0.594, v_num=sgwi, train_loss=0.635, val_loss=0.542]











Epoch 691:  83%|███████████████████████▎    | 40/48 [00:01<00:00, 33.07it/s, loss=0.559, v_num=sgwi, train_loss=0.440, val_loss=0.577]









Epoch 706:  83%|███████████████████████▎    | 40/48 [00:01<00:00, 32.71it/s, loss=0.543, v_num=sgwi, train_loss=0.521, val_loss=0.486]









Epoch 719: 100%|████████████████████████████| 48/48 [00:02<00:00, 23.65it/s, loss=0.562, v_num=sgwi, train_loss=0.623, val_loss=0.539]







Epoch 727:  83%|███████████████████████▎    | 40/48 [00:01<00:00, 30.43it/s, loss=0.565, v_num=sgwi, train_loss=0.481, val_loss=0.478]










Epoch 741:  83%|███████████████████████▎    | 40/48 [00:01<00:00, 31.87it/s, loss=0.538, v_num=sgwi, train_loss=0.462, val_loss=0.594]














Epoch 759:  83%|███████████████████████▎    | 40/48 [00:01<00:00, 31.70it/s, loss=0.594, v_num=sgwi, train_loss=0.558, val_loss=0.551]


















Epoch 782:  83%|████████████████████████▏    | 40/48 [00:01<00:00, 32.54it/s, loss=0.57, v_num=sgwi, train_loss=0.661, val_loss=0.589]















Epoch 802:  83%|███████████████████████▎    | 40/48 [00:01<00:00, 31.47it/s, loss=0.564, v_num=sgwi, train_loss=0.552, val_loss=0.522]
















Epoch 823: 100%|████████████████████████████| 48/48 [00:01<00:00, 24.77it/s, loss=0.549, v_num=sgwi, train_loss=0.420, val_loss=0.532]



Epoch 836:  83%|███████████████████████▎    | 40/48 [00:01<00:00, 35.13it/s, loss=0.584, v_num=sgwi, train_loss=0.708, val_loss=0.537]


Epoch 843:  83%|███████████████████████▎    | 40/48 [00:01<00:00, 35.25it/s, loss=0.593, v_num=sgwi, train_loss=0.662, val_loss=0.565]

Epoch 846:  83%|███████████████████████▎    | 40/48 [00:01<00:00, 35.58it/s, loss=0.516, v_num=sgwi, train_loss=0.560, val_loss=0.577]

Epoch 849:  83%|███████████████████████▎    | 40/48 [00:01<00:00, 36.53it/s, loss=0.544, v_num=sgwi, train_loss=0.594, val_loss=0.579]
















Epoch 867:  83%|███████████████████████▎    | 40/48 [00:01<00:00, 29.62it/s, loss=0.549, v_num=sgwi, train_loss=0.529, val_loss=0.554]


















Epoch 895:  83%|███████████████████████▎    | 40/48 [00:01<00:00, 32.82it/s, loss=0.544, v_num=sgwi, train_loss=0.583, val_loss=0.478]


Epoch 901:  83%|███████████████████████▎    | 40/48 [00:01<00:00, 32.54it/s, loss=0.559, v_num=sgwi, train_loss=0.593, val_loss=0.645]
























Epoch 944:  83%|███████████████████████▎    | 40/48 [00:01<00:00, 34.00it/s, loss=0.542, v_num=sgwi, train_loss=0.496, val_loss=0.592]

Epoch 946:  83%|███████████████████████▎    | 40/48 [00:01<00:00, 34.25it/s, loss=0.577, v_num=sgwi, train_loss=0.523, val_loss=0.590]




























Epoch 982:  83%|████████████████████████▏    | 40/48 [00:01<00:00, 32.57it/s, loss=0.55, v_num=sgwi, train_loss=0.497, val_loss=0.535]









Epoch 999: 100%|████████████████████████████| 48/48 [00:02<00:00, 22.50it/s, loss=0.556, v_num=sgwi, train_loss=0.404, val_loss=0.564]